{
 "metadata": {
  "kernelspec": {
   "language": "python",
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.7.12",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "Draft"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "#!pip install torch==1.11\n",
    "import torch as th \n",
    "import torchvision\n",
    "import numpy as np \n",
    "from torch.autograd import Variable\n",
    "import matplotlib.pyplot as plt \n",
    "from torchvision import datasets, transforms\n",
    "DATA_DIR = \"./\"\n",
    "train_ds = torchvision.datasets.MNIST(DATA_DIR, download=True,train=True, transform=transforms.ToTensor())\n",
    "test_ds = torchvision.datasets.MNIST(DATA_DIR, download=True,train=False, transform=transforms.ToTensor())\n",
    "\n",
    "#preprocessing = transforms.Compose([transforms.ToTensor(),\n",
    "                                   #transforms.Normalize(ds_mean, ds_var**0.5)\n",
    "#                                   ])\n",
    "# \n",
    "#train_ds = torchvision.datasets.MNIST(DATA_DIR, download=True,train=True, transform=preprocessing)\n",
    "#test_ds = torchvision.datasets.MNIST(DATA_DIR, download=True,train=False, transform=preprocessing)\n",
    "\n",
    "\n",
    "#x_train = train_ds.data.view(-1, 784) / 255. \n",
    "#y_train = train_ds.targets + 1 \n",
    "#x_test = test_ds.data.view(-1, 784) / 255.\n",
    "#y_test = test_ds.targets  + 1 \n",
    "dim = 784 \n",
    "K = 10 \n",
    "D = dim*K + 1 # 1 for lambda \n",
    "\n",
    "from torch import linalg as LA\n",
    "device = th.device(\"cuda\" if th.cuda.is_available() else \"cpu\")\n",
    "#x_test = x_test.to(device)\n",
    "#y_test = y_test.to(device)\n",
    "#x_train = x_train.to(device)\n",
    "#y_train = y_train.to(device)\n",
    "S = 100\n",
    "bsz = 4096\n",
    "trainloader = th.utils.data.DataLoader(train_ds, batch_size=S, shuffle=True)\n",
    "testloader = th.utils.data.DataLoader(test_ds, batch_size=10000, shuffle=True)\n",
    "total_steps = len(trainloader)\n",
    "#llimit = 1 \n",
    "N = len(train_ds)\n",
    "# \n",
    "#mean = (train_ds.data / 255.).mean(0).view(-1).to(device)\n",
    "#scale = (train_ds.data/255.).std(0).view(-1).to(device) + 1e-7 "
   ],
   "metadata": {
    "id": "bxwj53kmCzcc",
    "execution": {
     "iopub.status.busy": "2022-03-15T13:23:30.811888Z",
     "iopub.execute_input": "2022-03-15T13:23:30.812140Z",
     "iopub.status.idle": "2022-03-15T13:23:34.206213Z",
     "shell.execute_reply.started": "2022-03-15T13:23:30.812056Z",
     "shell.execute_reply": "2022-03-15T13:23:34.205472Z"
    },
    "trusted": true
   },
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "text": "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\nDownloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./MNIST/raw/train-images-idx3-ubyte.gz\n",
     "output_type": "stream"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "  0%|          | 0/9912422 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "50ef79c763554bc88a5f127f765a1d78"
      }
     },
     "metadata": {}
    },
    {
     "name": "stdout",
     "text": "Extracting ./MNIST/raw/train-images-idx3-ubyte.gz to ./MNIST/raw\n\nDownloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\nDownloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./MNIST/raw/train-labels-idx1-ubyte.gz\n",
     "output_type": "stream"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "  0%|          | 0/28881 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0a48e8edd76a48ac82bc1b346b7ceb26"
      }
     },
     "metadata": {}
    },
    {
     "name": "stdout",
     "text": "Extracting ./MNIST/raw/train-labels-idx1-ubyte.gz to ./MNIST/raw\n\nDownloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\nDownloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./MNIST/raw/t10k-images-idx3-ubyte.gz\n",
     "output_type": "stream"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "  0%|          | 0/1648877 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ce60d72499dc4bea800267bd0a9751e2"
      }
     },
     "metadata": {}
    },
    {
     "name": "stdout",
     "text": "Extracting ./MNIST/raw/t10k-images-idx3-ubyte.gz to ./MNIST/raw\n\nDownloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\nDownloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./MNIST/raw/t10k-labels-idx1-ubyte.gz\n",
     "output_type": "stream"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "  0%|          | 0/4542 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "36a39f42f1cc4afe92347399d44da60d"
      }
     },
     "metadata": {}
    },
    {
     "name": "stdout",
     "text": "Extracting ./MNIST/raw/t10k-labels-idx1-ubyte.gz to ./MNIST/raw\n\n",
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": "/opt/conda/lib/python3.7/site-packages/torchvision/datasets/mnist.py:498: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /usr/local/src/pytorch/torch/csrc/utils/tensor_numpy.cpp:174.)\n  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": "def loss_(dim=784, K=10):\n  def loss(x, y, param):\n    theta, _ = th.split(param, [dim*K, 1])\n    theta = theta.view(dim, K)\n    lambd = th.tensor(1e-1)\n    return (lambd / 2)*th.sum(th.square(theta)) - dim*K*th.log(lambd)/2  +  (1)*(th.sum(th.logsumexp(x @ theta, 1)) -th.trace(x @ theta[:, y])) #+ dim*K*np.log(2*np.pi)/2\n    #th.sum(th.log(th.sum(th.exp(x @ theta), dim=-1))) - th.trace(x @ theta[:, y -1])\n  return loss",
   "metadata": {
    "id": "eDkXsS1GFAwf",
    "execution": {
     "iopub.status.busy": "2022-03-15T13:23:34.208111Z",
     "iopub.execute_input": "2022-03-15T13:23:34.208600Z",
     "iopub.status.idle": "2022-03-15T13:23:34.215790Z",
     "shell.execute_reply.started": "2022-03-15T13:23:34.208550Z",
     "shell.execute_reply": "2022-03-15T13:23:34.215036Z"
    },
    "trusted": true
   },
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "criterion = loss_()\n@th.no_grad()\ndef validate(testloader, param):\n  total_loss = 0.\n  for (data, target) in testloader:\n        # putting data on device \n        data = data.to(device).view(-1, 784)\n        target = target.to(device).view(-1)\n        loss = criterion(data, target, param)\n        total_loss += loss.item()\n  return total_loss ",
   "metadata": {
    "id": "onTt8tKEapXd",
    "execution": {
     "iopub.status.busy": "2022-03-15T13:23:34.218133Z",
     "iopub.execute_input": "2022-03-15T13:23:34.218361Z",
     "iopub.status.idle": "2022-03-15T13:23:34.226881Z",
     "shell.execute_reply.started": "2022-03-15T13:23:34.218334Z",
     "shell.execute_reply": "2022-03-15T13:23:34.226138Z"
    },
    "trusted": true
   },
   "execution_count": 3,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "w = th.empty((D,1), device=device)\nw = th.nn.init.xavier_uniform_(w)\nparam = Variable(w.view(-1), requires_grad=True)",
   "metadata": {
    "id": "V5I18VsHZ77q",
    "execution": {
     "iopub.status.busy": "2022-03-15T13:23:34.229911Z",
     "iopub.execute_input": "2022-03-15T13:23:34.230386Z",
     "iopub.status.idle": "2022-03-15T13:23:37.040676Z",
     "shell.execute_reply.started": "2022-03-15T13:23:34.230347Z",
     "shell.execute_reply": "2022-03-15T13:23:37.039907Z"
    },
    "trusted": true
   },
   "execution_count": 4,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "losses = []\nval_losses = []\nepochs = 50\nlog_freq = 2 \nB = 3*th.eye(D)\nB[-1,-1] = 0 # lambda is fixed \nC = B@B.T\neps = 2*D*S / N / th.trace(C) # eq17\nH = 2*S/eps/N/C.diag() # eq19\nH = th.diag(H).to(device)\noptimizer  = th.optim.SGD([param], lr=eps)\neps",
   "metadata": {
    "id": "jDmwqs_Fa5Sm",
    "execution": {
     "iopub.status.busy": "2022-03-15T13:23:37.043149Z",
     "iopub.execute_input": "2022-03-15T13:23:37.043634Z",
     "iopub.status.idle": "2022-03-15T13:23:44.180323Z",
     "shell.execute_reply.started": "2022-03-15T13:23:37.043593Z",
     "shell.execute_reply": "2022-03-15T13:23:44.179641Z"
    },
    "trusted": true
   },
   "execution_count": 5,
   "outputs": [
    {
     "execution_count": 5,
     "output_type": "execute_result",
     "data": {
      "text/plain": "tensor(0.0004)"
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "code",
   "source": "for e in range(epochs):\n  # compute loss \n  for i, (data, target) in enumerate(trainloader):\n        # putting data on device \n        data = data.to(device).view(-1, 784) #- mean \n        #data = data / scale\n        target = target.to(device).view(-1)\n        # making mini batch \n        idx = np.random.choice(data.size(0), S) #TODO cas mbsz >= data.size(0)\n        #theta.grad.data.zero_()\n        #loglambd.grad.data.zero_()\n        loss = criterion(data, target, param)\n        # back prop \n        optimizer.zero_grad()\n        loss.backward()\n        #print(theta.grad[0])\n        param = Variable(param.detach() - eps*H@param.grad.data, requires_grad=True) \n        #loglambd = loglambd.detach() - eps*loglambd.grad.data\n        #loglambd.requires_grad = True \n        #print(theta)\n        #optimizer.step()\n        if i% (total_steps//log_freq) ==0:\n          val_loss =  validate(testloader, param)\n          print(f\"Epoch:{e+1:3d}/{epochs} step {i+1:3d} / {total_steps} loss: {loss.item():9.2f} validation loss : #{val_loss:9.2f}\") \n          losses.append(loss.item())\n          val_losses.append(val_loss)",
   "metadata": {
    "id": "Nf8_qaC2jANO",
    "outputId": "bef11b92-4dd3-4397-9728-3053e56320c3",
    "execution": {
     "iopub.status.busy": "2022-03-15T13:23:44.181485Z",
     "iopub.execute_input": "2022-03-15T13:23:44.181734Z",
     "iopub.status.idle": "2022-03-15T13:29:14.656890Z",
     "shell.execute_reply.started": "2022-03-15T13:23:44.181700Z",
     "shell.execute_reply": "2022-03-15T13:29:14.656142Z"
    },
    "trusted": true
   },
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "text": "Epoch:  1/50 step   1 / 600 loss:   9262.89 validation loss : # 32211.04\nEpoch:  1/50 step 301 / 600 loss:   9074.18 validation loss : # 14724.20\nEpoch:  2/50 step   1 / 600 loss:   9084.22 validation loss : # 13618.96\nEpoch:  2/50 step 301 / 600 loss:   9071.90 validation loss : # 13209.97\nEpoch:  3/50 step   1 / 600 loss:   9056.76 validation loss : # 12936.23\nEpoch:  3/50 step 301 / 600 loss:   9067.03 validation loss : # 12772.36\nEpoch:  4/50 step   1 / 600 loss:   9067.64 validation loss : # 12658.82\nEpoch:  4/50 step 301 / 600 loss:   9060.62 validation loss : # 12571.23\nEpoch:  5/50 step   1 / 600 loss:   9058.38 validation loss : # 12504.63\nEpoch:  5/50 step 301 / 600 loss:   9056.61 validation loss : # 12439.89\nEpoch:  6/50 step   1 / 600 loss:   9063.49 validation loss : # 12406.59\nEpoch:  6/50 step 301 / 600 loss:   9081.76 validation loss : # 12364.24\nEpoch:  7/50 step   1 / 600 loss:   9053.18 validation loss : # 12327.36\nEpoch:  7/50 step 301 / 600 loss:   9058.46 validation loss : # 12296.34\nEpoch:  8/50 step   1 / 600 loss:   9092.14 validation loss : # 12265.62\nEpoch:  8/50 step 301 / 600 loss:   9061.15 validation loss : # 12249.91\nEpoch:  9/50 step   1 / 600 loss:   9063.71 validation loss : # 12224.48\nEpoch:  9/50 step 301 / 600 loss:   9062.40 validation loss : # 12217.59\nEpoch: 10/50 step   1 / 600 loss:   9065.28 validation loss : # 12194.86\nEpoch: 10/50 step 301 / 600 loss:   9063.64 validation loss : # 12186.39\nEpoch: 11/50 step   1 / 600 loss:   9059.83 validation loss : # 12168.29\nEpoch: 11/50 step 301 / 600 loss:   9075.43 validation loss : # 12156.22\nEpoch: 12/50 step   1 / 600 loss:   9067.16 validation loss : # 12139.31\nEpoch: 12/50 step 301 / 600 loss:   9062.42 validation loss : # 12136.14\nEpoch: 13/50 step   1 / 600 loss:   9058.94 validation loss : # 12126.67\nEpoch: 13/50 step 301 / 600 loss:   9053.86 validation loss : # 12117.75\nEpoch: 14/50 step   1 / 600 loss:   9057.58 validation loss : # 12108.17\nEpoch: 14/50 step 301 / 600 loss:   9047.89 validation loss : # 12095.91\nEpoch: 15/50 step   1 / 600 loss:   9072.00 validation loss : # 12087.28\nEpoch: 15/50 step 301 / 600 loss:   9069.96 validation loss : # 12083.18\nEpoch: 16/50 step   1 / 600 loss:   9052.47 validation loss : # 12077.35\nEpoch: 16/50 step 301 / 600 loss:   9065.40 validation loss : # 12065.44\nEpoch: 17/50 step   1 / 600 loss:   9057.92 validation loss : # 12069.12\nEpoch: 17/50 step 301 / 600 loss:   9062.53 validation loss : # 12063.98\nEpoch: 18/50 step   1 / 600 loss:   9059.29 validation loss : # 12057.43\nEpoch: 18/50 step 301 / 600 loss:   9063.67 validation loss : # 12053.86\nEpoch: 19/50 step   1 / 600 loss:   9057.74 validation loss : # 12048.63\nEpoch: 19/50 step 301 / 600 loss:   9060.39 validation loss : # 12048.40\nEpoch: 20/50 step   1 / 600 loss:   9058.17 validation loss : # 12048.26\nEpoch: 20/50 step 301 / 600 loss:   9060.31 validation loss : # 12046.69\nEpoch: 21/50 step   1 / 600 loss:   9057.83 validation loss : # 12024.75\nEpoch: 21/50 step 301 / 600 loss:   9053.75 validation loss : # 12033.03\nEpoch: 22/50 step   1 / 600 loss:   9056.55 validation loss : # 12023.99\nEpoch: 22/50 step 301 / 600 loss:   9063.67 validation loss : # 12019.50\nEpoch: 23/50 step   1 / 600 loss:   9065.33 validation loss : # 12016.83\nEpoch: 23/50 step 301 / 600 loss:   9058.88 validation loss : # 12024.29\nEpoch: 24/50 step   1 / 600 loss:   9065.09 validation loss : # 12023.31\nEpoch: 24/50 step 301 / 600 loss:   9055.12 validation loss : # 12010.86\nEpoch: 25/50 step   1 / 600 loss:   9058.24 validation loss : # 12004.79\nEpoch: 25/50 step 301 / 600 loss:   9058.97 validation loss : # 12002.30\nEpoch: 26/50 step   1 / 600 loss:   9059.33 validation loss : # 12004.16\nEpoch: 26/50 step 301 / 600 loss:   9058.27 validation loss : # 12011.14\nEpoch: 27/50 step   1 / 600 loss:   9060.35 validation loss : # 12001.79\nEpoch: 27/50 step 301 / 600 loss:   9051.18 validation loss : # 12004.45\nEpoch: 28/50 step   1 / 600 loss:   9050.29 validation loss : # 11998.15\nEpoch: 28/50 step 301 / 600 loss:   9055.97 validation loss : # 11994.16\nEpoch: 29/50 step   1 / 600 loss:   9059.24 validation loss : # 11991.80\nEpoch: 29/50 step 301 / 600 loss:   9053.17 validation loss : # 11982.54\nEpoch: 30/50 step   1 / 600 loss:   9069.40 validation loss : # 11990.22\nEpoch: 30/50 step 301 / 600 loss:   9066.31 validation loss : # 11999.51\nEpoch: 31/50 step   1 / 600 loss:   9055.26 validation loss : # 11989.46\nEpoch: 31/50 step 301 / 600 loss:   9051.54 validation loss : # 11979.67\nEpoch: 32/50 step   1 / 600 loss:   9067.60 validation loss : # 11979.83\nEpoch: 32/50 step 301 / 600 loss:   9055.33 validation loss : # 11978.29\nEpoch: 33/50 step   1 / 600 loss:   9053.96 validation loss : # 11981.24\nEpoch: 33/50 step 301 / 600 loss:   9057.10 validation loss : # 11973.98\nEpoch: 34/50 step   1 / 600 loss:   9061.48 validation loss : # 11980.82\nEpoch: 34/50 step 301 / 600 loss:   9059.64 validation loss : # 11971.84\nEpoch: 35/50 step   1 / 600 loss:   9057.57 validation loss : # 11979.44\nEpoch: 35/50 step 301 / 600 loss:   9055.49 validation loss : # 11987.64\nEpoch: 36/50 step   1 / 600 loss:   9052.57 validation loss : # 11974.96\nEpoch: 36/50 step 301 / 600 loss:   9054.40 validation loss : # 11977.18\nEpoch: 37/50 step   1 / 600 loss:   9055.69 validation loss : # 11969.25\nEpoch: 37/50 step 301 / 600 loss:   9065.65 validation loss : # 11965.06\nEpoch: 38/50 step   1 / 600 loss:   9053.59 validation loss : # 11972.19\nEpoch: 38/50 step 301 / 600 loss:   9065.46 validation loss : # 11965.51\nEpoch: 39/50 step   1 / 600 loss:   9068.96 validation loss : # 11968.83\nEpoch: 39/50 step 301 / 600 loss:   9055.40 validation loss : # 11974.90\nEpoch: 40/50 step   1 / 600 loss:   9055.43 validation loss : # 11968.35\nEpoch: 40/50 step 301 / 600 loss:   9059.93 validation loss : # 11965.67\nEpoch: 41/50 step   1 / 600 loss:   9052.58 validation loss : # 11967.12\nEpoch: 41/50 step 301 / 600 loss:   9055.87 validation loss : # 11967.15\nEpoch: 42/50 step   1 / 600 loss:   9064.53 validation loss : # 11959.11\nEpoch: 42/50 step 301 / 600 loss:   9062.99 validation loss : # 11962.39\nEpoch: 43/50 step   1 / 600 loss:   9068.34 validation loss : # 11966.05\nEpoch: 43/50 step 301 / 600 loss:   9055.90 validation loss : # 11959.88\nEpoch: 44/50 step   1 / 600 loss:   9051.87 validation loss : # 11963.05\nEpoch: 44/50 step 301 / 600 loss:   9054.44 validation loss : # 11963.82\nEpoch: 45/50 step   1 / 600 loss:   9054.70 validation loss : # 11961.65\nEpoch: 45/50 step 301 / 600 loss:   9073.62 validation loss : # 11961.10\nEpoch: 46/50 step   1 / 600 loss:   9065.77 validation loss : # 11956.04\nEpoch: 46/50 step 301 / 600 loss:   9078.69 validation loss : # 11965.14\nEpoch: 47/50 step   1 / 600 loss:   9062.51 validation loss : # 11952.66\nEpoch: 47/50 step 301 / 600 loss:   9063.54 validation loss : # 11947.98\nEpoch: 48/50 step   1 / 600 loss:   9049.79 validation loss : # 11954.23\nEpoch: 48/50 step 301 / 600 loss:   9048.89 validation loss : # 11955.62\nEpoch: 49/50 step   1 / 600 loss:   9048.35 validation loss : # 11956.71\nEpoch: 49/50 step 301 / 600 loss:   9058.75 validation loss : # 11951.48\nEpoch: 50/50 step   1 / 600 loss:   9058.15 validation loss : # 11952.87\nEpoch: 50/50 step 301 / 600 loss:   9066.52 validation loss : # 11955.60\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": "plt.semilogy(val_losses, label=\"val\")\nplt.semilogy(losses, label=\"train\")\nplt.legend()",
   "metadata": {
    "id": "UfHd9S7f4OhZ",
    "execution": {
     "iopub.status.busy": "2022-03-15T13:29:14.658030Z",
     "iopub.execute_input": "2022-03-15T13:29:14.658441Z",
     "iopub.status.idle": "2022-03-15T13:29:15.572570Z",
     "shell.execute_reply.started": "2022-03-15T13:29:14.658405Z",
     "shell.execute_reply": "2022-03-15T13:29:15.571905Z"
    },
    "trusted": true
   },
   "execution_count": 7,
   "outputs": [
    {
     "execution_count": 7,
     "output_type": "execute_result",
     "data": {
      "text/plain": "<matplotlib.legend.Legend at 0x7f826448c390>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ]
  }
 ]
}